{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44d6e17f-25d9-4d8d-aaca-52de2f9041fa",
   "metadata": {},
   "source": [
    "# Assignment 5\n",
    "First, run the below cells to ensure you install the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b7e00b-2d15-47ee-bb1e-f323fe0295ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install kipoiseq==0.5.2 \n",
    "!pip install logomaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73150748-2811-42cd-b90a-5ce5abce45ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install enformer-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c41dde5-0084-4e29-8734-a69d92166505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enformer_pytorch import from_pretrained\n",
    "from enformer_pytorch.finetune import HeadAdapterWrapper\n",
    "import kipoiseq\n",
    "from kipoiseq import Interval\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyfaidx\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "from transformers import GPT2Model, GPT2Tokenizer\n",
    "import seaborn as sns\n",
    "import logomaker\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82853785-b6be-461f-94f1-16e89b6296bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a783603a-5583-41c7-8a32-f570384a0c55",
   "metadata": {},
   "source": [
    "## Question 1: Self-attention\n",
    "Self-attention allows a model to weigh the importance of different tokens in a sequence relative to each other. This allows it to capture dependencies across the entire input, so the model can learn both local and long-range relationships. In this question, you will take a look at how self-attention works for natural language by using GPT-2 and visualizing the attention weights as a heatmap. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27fdc89-bafe-41de-a235-ac02e482e919",
   "metadata": {},
   "source": [
    "### Question 1a - Self-attention in GPT-2\n",
    "We will now look at how the attention weights change as we go deeper into the attention network. GPT-2 comprises of a 12-layer decoder. We will visualize what the attention weights look like for the input sentence \"The quick brown fox jumps over the lazy dog.\" by visualizing it as a heatmap where the x-axis are all the key tokens of the sentence, and the y-axis are all query tokens of the sentence. You will visualize the first layer (0th layer), an intermediate layer (2nd layer), a middle layer (6th layer) and a deep layer (11th layer); we will use 0-indexing. Stick with only visualizing the 0th head. You will see a special `Ä ` character, which is just a special character to represent spaces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89bf10b-86e5-47a6-a4d2-6c51131fb8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model and tokenizer\n",
    "model = GPT2Model.from_pretrained(\"gpt2\", output_attentions=True)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Input sentence\n",
    "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# Tokenize the input sentence\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "\n",
    "# Forward pass through the model\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Extract attention from the model output\n",
    "attentions = outputs.attentions  # list of attention weights for each layer\n",
    "\n",
    "# Attention for each layer is of size [1, 12, n, n] where:\n",
    "# 1 is the batch size\n",
    "# 12 is the number of heads\n",
    "# n is the number of tokens in the input sentence\n",
    "\n",
    "# Visualize the attention weights as a heatmap\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "\n",
    "# TODO: Code for heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60867d4-00d4-403f-8a5e-691abbeec143",
   "metadata": {},
   "source": [
    "### Question 1b - Discussion\n",
    "As you analyze the heatmaps from different layers, what changes do you observe in the patterns going from shallow to deeper layers. How might these changes reflect the model's understanding of the sentence structure and meaning? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ac279f-027d-4a1e-b6eb-b6e1201db6f4",
   "metadata": {},
   "source": [
    "-insert written answer here-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e61c313-86df-4786-b88a-cb1323168432",
   "metadata": {},
   "source": [
    "### Question 1c - Changing the sentence structure\n",
    "Now, we will do the same analysis (same layers) on the passive version of the sentence: \"The lazy dog was jumped over by the quick brown fox.\" Repeat Question 1a with this new sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b493b9-d9a1-4351-90a3-38f945173146",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The lazy dog was jumped over by the quick brown fox.\"\n",
    "\n",
    "# TODO: Code to extract attention weights and plot heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca238587-57a5-4ba0-8615-a2083cc8bc12",
   "metadata": {},
   "source": [
    "### Question 1d - Discussion \n",
    "Compare the attention heatmaps of the active and passive versions of the sentence. How do the attention patterns differ? Look in particular at the subject, verb and object of the sentence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cf546c-c962-4f3a-b403-a6dd69fb8e9b",
   "metadata": {},
   "source": [
    "-insert written answer here-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a688af6-27e3-412f-b7ca-e733048733ca",
   "metadata": {},
   "source": [
    "## Question 2 - One-Hot Encoding\n",
    "One-hot encoding is a common method for representing DNA sequences in a format that machine learning models can process. In this question, you will implement one-hot encoding. \n",
    "\n",
    "### Question 2a: Implementation\n",
    "Complete the function to one-hot encode the given DNA sequence. The one-hot encoding should be in alphabetical order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cabccf-5d10-43cf-a0a4-920956988e99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encode_dna(sequence):\n",
    "    # TODO: code for one-hot encoding DNA sequence\n",
    "    \n",
    "    return one_hot_encoded\n",
    "\n",
    "# Example DNA sequence\n",
    "dna_sequence = 'TCTCCAGTGCCCAAGACCACGGGCGCTCGGCGCCTTGGCTAATCCCCGTACATGTTGTTATAAATAATCAGTAGAAAGTCTGTGTTAGAGGGTGGAGTGA'\n",
    "\n",
    "# One-hot encode the sequence\n",
    "one_hot_encoded_dna = one_hot_encode_dna(dna_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a20426d-6a15-49db-b5d7-768c861e61bd",
   "metadata": {},
   "source": [
    "### Question 2b: Plot\n",
    "Make a plot to visualize the one-hot encoding. The y-axis will be the four nucleotides, and the x-axis will be each position of the DNA sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476b907d-55f9-487a-8e34-b1ddaae4d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Code for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea59590e-6d98-46b5-a854-143617c44ee4",
   "metadata": {},
   "source": [
    "### Question 2c: Discussion\n",
    "What are some advantages and limitations of using one-hot encoding in neural networks? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ce920e-a2e9-42c8-970a-5b78e9c38112",
   "metadata": {},
   "source": [
    "-insert written answer here-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11d4e17-1f19-4092-aab3-9afd7b47c1cc",
   "metadata": {},
   "source": [
    "## Question 3: Motif Classification\n",
    "### Question 3a: One-Hot Encoding and PCA\n",
    "In this question, you will classify transcription factor sequence motifs from the [JASPAR database](https://jaspar.elixir.no/). We provide two files: `training.txt` which contains 2500 training examples (500 examples from 5 different transcription factors) and `validation.txt` which contains 500 examples from these 5 TFs that can be used for validating your model. Using your function from Question 2, convert the sequences into numerical data by using one-hot encoding to represent the DNA sequences as binary vectors. The encoded sequences can then be used for PCA. Plot the first 2 components of the training data (`training.txt`) and color the points by their label (transcription factor). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07d7f68-327e-4842-9c03-a21fd575cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "training_txt = pd.read_csv('training.txt', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb574b3-3620-4bc7-9b8c-4a9aa8213dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_sequences = training_txt[[0]].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8621df-95af-467e-ae9c-9fad6213f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform one-hot encoding (Hint: make sure to make it a numpy array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6feb101-a814-42f4-8d11-09d5629294ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the one-hot encoded data\n",
    "flattened_data = one_hot_encoded_sequences.reshape(one_hot_encoded_sequences.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad839fa-09f8-4991-9111-ee2f850c94a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(flattened_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a054475e-fd39-42d5-b86a-2f776bea5779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Code for PCA and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b65a447-1aea-435d-9bba-8b7bf6e31463",
   "metadata": {},
   "source": [
    "### Question 3b: Convolutional Neural Network\n",
    "Implement a simple convolutional neural network using PyTorch. You can refer to the neural network we provided in Assignment 4 as a template for a CNN model class as well as the code for the training procedure. In a few sentences, describe your model architecture you decided to use and why. Plot the training loss per epoch. For a simple PyTorch tutorial based on image data, you can refer to [this tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd503ba6-66aa-4ccf-a4bd-175e0e4e1c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train = torch.tensor(label_encoder.fit_transform(training_txt[[1]].values.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ed09fd-00f8-41ce-a4d0-458090668c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_sequences_reshaped = one_hot_encoded_sequences.transpose(0, 2, 1)\n",
    "X_train = torch.tensor(one_hot_encoded_sequences_reshaped , dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca33b59c-991b-4c6e-91c4-9758b79f9d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce96fdf-c2a2-4648-943c-0ae8abbc9c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Code for defining a CNN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd18db7-a1bf-47db-9d4f-220c1574161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Code for training CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bb05d3-29ae-4b2a-b92b-6573148c811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Code for plotting loss over epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9337c8e-1600-43c5-af40-6f4421a027f3",
   "metadata": {},
   "source": [
    "-insert written answer here-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d06f4e5-e59a-4c9c-b4f6-8bd0e5e32145",
   "metadata": {},
   "source": [
    "### Question 3c - Evaluation\n",
    "Now use the labeled data in `validation.txt` to evaluate the accuracy of your model. Use `classification_report` to show the accuracy for each TF. Make sure to comment on the accuracy for each transcription factor separately. Also comment on why certain transcription factors are harder than others (Hint: How do the hardest ones appear in the PCA plot). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355df20b-471a-47b5-a214-7ea0735b55ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation data\n",
    "val_txt = pd.read_csv('validation.txt', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527f7eda-f715-4c9d-b019-43eaf8e458f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Code for processing validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f8abfc-81f9-4a74-9139-3c6b1d220925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Code for predicting TFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00642ba-6715-49b1-92e5-6879083e012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Code for evaluating accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf15227-2a3a-4d05-ae9c-1cfcb6fcfa1f",
   "metadata": {},
   "source": [
    "-insert written answer here-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4adafe2-0ce6-4543-852d-3eef3126b1f6",
   "metadata": {},
   "source": [
    "## Question 4: Enformer\n",
    "Enformer is an attention network developed by DeepMind to predict gene expression from DNA sequences. It is built on the Transformer architecture which allows it to capture the effects of regulatory elements that are located far away from the location of genes they regulate. You can learn more about Enformer from the [original publication](https://www.nature.com/articles/s41592-021-01252-x). We will use the pre-trained Enformer model to explore the inner workings of a Transformer. The input to the Enformer model is a one-hot encoded DNA sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2ac471-f6f4-4e10-8979-8dd58a33bcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for extracting DNA sequences from a FASTA file\n",
    "class FastaStringExtractor:\n",
    "    def __init__(self, fasta_file):\n",
    "        self.fasta = pyfaidx.Fasta(fasta_file)\n",
    "        self._chromosome_sizes = {k: len(v) for k, v in self.fasta.items()}\n",
    "\n",
    "    def extract(self, interval: Interval, **kwargs) -> str:\n",
    "        # Truncate interval if it extends beyond the chromosome lengths.\n",
    "        chromosome_length = self._chromosome_sizes[interval.chrom]\n",
    "        trimmed_interval = Interval(interval.chrom,\n",
    "                                    max(interval.start, 0),\n",
    "                                    min(interval.end, chromosome_length),\n",
    "                                    )\n",
    "        # pyfaidx wants a 1-based interval\n",
    "        sequence = str(self.fasta.get_seq(trimmed_interval.chrom,\n",
    "                                          trimmed_interval.start + 1,\n",
    "                                          trimmed_interval.stop).seq).upper()\n",
    "        # Fill truncated values with N's.\n",
    "        pad_upstream = 'N' * max(-interval.start, 0)\n",
    "        pad_downstream = 'N' * max(interval.end - chromosome_length, 0)\n",
    "        return pad_upstream + sequence + pad_downstream\n",
    "\n",
    "    def close(self):\n",
    "        return self.fasta.close()\n",
    "\n",
    "# Function to one-hot encode DNA sequences\n",
    "def one_hot_encode(sequence):\n",
    "  return kipoiseq.transforms.functional.one_hot_dna(sequence).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b13740-c137-4309-ac79-3bc5b87190a4",
   "metadata": {},
   "source": [
    "We will also load up a metadata dataframe that contains the names of each Enformer track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb6ed8a-ba23-4306-b0c1-9439b8557f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv('targets.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a4ee0f-c070-4966-a2d5-13dcfc60e8bd",
   "metadata": {},
   "source": [
    "### Question 4a - Prediction of gene expression\n",
    "We will now investigate the output predictions of Enformer. The structure of the output for Enformer is as follows: there are 200 columns, corresponding to 200 120-bp window along the genome interval, with the value being the activity for each window; there are also 5313 rows, corresponding to 5313 different tracks that are predicted by Enformer. Each track refers to a different type of functional genomic feature or signal, such as DNase-seq, ChIP-seq, and ATAC-seq. \n",
    "\n",
    "You will run Enformer on an interval of chromosome 11, and obtain the predicted tracks. For that interval, plot and label:\n",
    "1. the track with the highest **mean** activity\n",
    "2. the track with the lowest **mean** activity\n",
    "3. the track with the highest **peak** activity\n",
    "\n",
    "We have provided you the function to plot the track, as well as an example visualization of a random track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252d66cf-5e5f-4058-adf1-d290a68f4126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the predictions of Enformer\n",
    "def plot_tracks(y, title, interval, height=1.5):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(20, height), sharex=True)\n",
    "    ax.fill_between(np.linspace(interval.start, interval.end, num=len(y)), y)\n",
    "    ax.set_title(title)\n",
    "    sns.despine(top=True, right=True, bottom=True)\n",
    "    ax.set_xlabel(str(interval))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0cf302-9ab0-4a35-af58-3d2fa4574371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained Enformer model\n",
    "enformer = from_pretrained('EleutherAI/enformer-official-rough', use_tf_gamma=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a42a88-d022-46b2-ac5d-11ae91ff7661",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1d57cc-cde0-4b51-a06e-fcb29e45799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract DNA sequence of chromosome 11\n",
    "fasta_extractor = FastaStringExtractor('chr11.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d73e3f-4cfe-4185-81d9-7261c37c72b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 25_600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a675fd12-0fb4-4bc0-8227-2d15a071d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on a defined interval of chromosome 11\n",
    "mid = 35_140_086\n",
    "target_interval = kipoiseq.Interval('chr11', mid-SEQUENCE_LENGTH//2, mid+SEQUENCE_LENGTH//2)\n",
    "\n",
    "# One-hot encode DNA and make it into a tensor\n",
    "sequence_tensor = torch.from_numpy(one_hot_encode(fasta_extractor.extract(target_interval.resize(SEQUENCE_LENGTH)))).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4ca6fa-b734-4ba4-a694-87486f9e9f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain predictions from Enformer and convert to a numpy array\n",
    "predictions = enformer(sequence_tensor, target_length=SEQUENCE_LENGTH//128)['human']\n",
    "np_predictions = predictions.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82798de-3f6e-45df-966d-32a3083b8732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a random track as an example (track #41)\n",
    "plot_tracks(np_predictions[:, 41], metadata_df.loc[41].description, target_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abdd4aa-567a-4197-b9e0-f687e627f167",
   "metadata": {},
   "source": [
    "#### Highest mean activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cca8a85-fafe-4e8f-ad85-1d87df2dd746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Code for getting track with highest mean activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400cb292-f7cd-4919-8f22-22003ffc8ad9",
   "metadata": {},
   "source": [
    "#### Lowest mean activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20357a36-5123-4914-bee7-ff8779ac6c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Code for getting track with lowest mean activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669e0748-6aef-4be2-b78f-8cfb54384287",
   "metadata": {},
   "source": [
    "#### Highest peak activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a80ad5-64e1-4905-beac-d84033c459d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Code for getting track with highest peak activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b94af2-074e-4da0-a361-2c6174908259",
   "metadata": {},
   "source": [
    "### Question 4b - Convolution Analysis\n",
    "We will now dive deeper into the convolutional layers of Enformer to determine what it is exactly doing. In Enformer, each convolutional filter in the first convolutional layer represents a generalization of a DNA motif. However, they are not exact motifs, and account for base variations at each position. We will generate motif plots for specific filters, where the signal of each nucleotide at each position can be observed. First, we will plot the first filter. Comment on how to interpret the plot, and give the most likely motif from the first filter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8917aabd-736a-49f0-a0a0-54ec9dd94364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot a motif of a filter\n",
    "def logo_plot(filter, idx, base_title=\"Enformer stem convolution 1 filter\"):\n",
    "    filter_df = pd.DataFrame(filter).astype(float)\n",
    "    filter_df.columns = [\"A\",\"C\",\"G\",\"T\"]\n",
    "    plt.figure()\n",
    "    logo = logomaker.Logo(filter_df)\n",
    "    logo.style_spines(visible=False)\n",
    "    logo.style_spines(spines=['left', 'bottom'], visible=True)\n",
    "    logo.style_xticks(rotation=90, fmt='%d', anchor=0)\n",
    "    logo.ax.set_title(f\"{base_title} {idx}\")\n",
    "    logo.ax.xaxis.set_ticks_position('none')\n",
    "    logo.ax.xaxis.set_tick_params(pad=-1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdad736-322e-4641-88a3-bc9a6b4db311",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filters, n_channels, n_positions = enformer.stem[0].weight.shape\n",
    "conv_weights = enformer.stem[0].weight.detach().cpu().numpy().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6e0be3-81b2-4800-9772-8fce66649d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_filter = 0\n",
    "interest_weights = conv_weights[interest_filter,:,:].T\n",
    "logo_plot(interest_weights, interest_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf79d47-5605-49dc-9073-adfe077ef470",
   "metadata": {},
   "source": [
    "-insert written answer here-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa710c9-31e5-4ddc-ba42-4e5d98876b61",
   "metadata": {},
   "source": [
    "### Question 4c - Find motif with the strongest signal \n",
    "Now, you must find the motif with the strongest signal. (Hint: you will want to look at absolute signal values). Use the plot and extract the motif with the strongest signal. Use [Tomtom](https://meme-suite.org/meme/tools/tomtom) to search the motif sequence. The top hit should contain a link for more information. What is the name of this motif? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8440e0-bd2c-4a90-8781-68540f158a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Code for finding motif with the strongest signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89218da4-5f37-4311-ae5c-eca889351e69",
   "metadata": {},
   "source": [
    "### Question 4d - Finding most closely related filter to a motif\n",
    "You will use a MYOD1 motif from Question 2, and find out which Enformer filter would likely represent that motif. Visualize the motif using the same plot as before. Comment on how similar the MYOD1 motif sequence is to the motif in Enformer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edcaa9b-1a60-405c-ae5a-2454a8d1b37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 'GCGCAGCTGTCCTGA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2cc15c-b7e5-47d1-931e-d37d658c4569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Code for finding the most closely related filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cb1dd6-c582-4c86-b549-c9c898ae7571",
   "metadata": {},
   "source": [
    "-insert written answer here-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
