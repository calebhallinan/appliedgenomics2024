{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6449375-f71e-4bf5-85cb-8173e1f53be4",
   "metadata": {},
   "source": [
    "# Assignment 4: RNA-seq and Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b1f74b-f59c-4cf9-99f9-2410c1c6ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import umap\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1211461-ec73-49ec-a2db-ea88deebd446",
   "metadata": {},
   "source": [
    "## Question 1: Differential Expression\n",
    "### Question 1a - Sample 5000 rows\n",
    "In the files [data1.txt](data1.txt) and [data2.txt](data2.txt), we provide an abstraction of RNA-seq data with 100,000 lines of RNA-seq data where normalization has been performed and the number of times a gene name occurs corresponds to the number of transcripts in the sample. Randomly sample 5000 rows from each file. Sample 3 times for each file (this emulates making experimental replicates) and conduct a paired t-test for differential expression of each of the 15 genes. Which genes are significantly differentially expressed at the 0.05 level and what is their mean fold change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73c7090-bc91-4d89-adc8-f14ca91dc9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Insert code "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067f4aaf-b8cb-4d4e-928c-76fa32d21476",
   "metadata": {},
   "source": [
    "### Question 1b - Volcano plot\n",
    "Make a volano plot of the data from part a: x-axis=log2(fold change of the mean expression of gene_i); y-axis=-log_10(p_value comparing the expression of gene_i). Label all of the genes that show a statistically siginificant change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63bafb7-8e66-41f8-87db-3af7164bea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bbe66c-8257-47ea-a789-2590a26400ae",
   "metadata": {},
   "source": [
    "### Question 1c - Sample 5000 rows 10 times\n",
    "Now sample 5000 rows 10 times from each file, equivalent to making more replicates. Which genes are now significant at the 0.05 level and what is their mean fold change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b120029-e048-4acb-bda1-1052b4573816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a012b2-3271-4613-ad5d-88fc62b8e93e",
   "metadata": {},
   "source": [
    "### Question 1d - Volcano plot 2\n",
    "Make a volcano plot using the results from part c (label any statistically significant genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a2056c-8f06-4ea9-8d0b-ea870e026309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7924ba3a-e4c3-418b-88b2-814b5efa978f",
   "metadata": {},
   "source": [
    "### Question 1e - Sample 50 000 rows\n",
    "Perform the simulations from parts a/c but sample 50000 rows each time from each file. Which genes are significant and what is their mean fold change? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c6bc62-c042-486c-8498-e94f40937ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcea66e0-b11c-452e-a9ec-c2cd79acf400",
   "metadata": {},
   "source": [
    "### Question 1f - Volcano plot 3\n",
    "Make a volcano plot from 5e (label any statistically significant genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6f02f2-5a8e-4b57-8e78-0fcd3b1905f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cd4616-132d-411c-a616-3d259917bf28",
   "metadata": {},
   "source": [
    "### Question 1g - Comparison\n",
    "Now examine the complete files: compare the fold change in the complete files vs the different subsamples making sure to address replicates and the size of the random sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e2f226-b227-4b18-b2c5-a45d5b507cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd196df3-4f96-4067-8364-4e2c13e564bb",
   "metadata": {},
   "source": [
    "-insert written answer here-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ec483d-25c5-47eb-857a-3152be92d3af",
   "metadata": {},
   "source": [
    "## Question 2: Exploratory Data Analysis\n",
    "First let's load up our data. The data is split into a training and a testing dataset. The `X` files contain the gene expression matrix where the columns represent genes and the rows represent samples taken. The `y` files contain the labels for each sample (i.e. the tissue type). These files are split into a training and a testing dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ea6ba4-8a8b-4976-9b87-a083d91dcc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data_files/X_train.tsv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79032f8e-e77f-4fd1-94f4-7c28e41f3eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv('data_files/y_train.tsv', sep='\\t', index_col=0).values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b732317-a7e9-4fb2-8bdb-c41f974cb6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('data_files/X_test.tsv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c193f98-ec11-47df-9ec0-37edb286503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.read_csv('data_files/y_test.tsv', sep='\\t', index_col=0).values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9980c5b1-0510-4819-baf0-712c225cb611",
   "metadata": {},
   "source": [
    "### Normalize gene expression\n",
    "We must first use `StandardScaler` to normalize the expression data for each gene. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebb84d5-e50f-4133-bb17-42ecaa151d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7928bd35-c202-4fff-9520-4a7d6538440f",
   "metadata": {},
   "source": [
    "### Dimensionality reduction\n",
    "Now let's perform dimensionality reduction and visualize the data. This is always an important step for machine learning to better understand the distribution of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1df908-abfe-40ce-9c75-e7856e638254",
   "metadata": {},
   "source": [
    "### Question 2a - PCA\n",
    "Calculate the first two principal components on the **training** expression matrix. Show the plot and color the points based on tissue type (`y_train`). Are there any tissue types that appear distinct from the others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d38f33-c893-4b7b-b58b-0f58cc5cafae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0be3726-3b8a-43a0-892f-58bf4817ff4b",
   "metadata": {},
   "source": [
    "-insert written answer here-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc38952-17b5-4527-b686-c9484ea02e2d",
   "metadata": {},
   "source": [
    "### Question 2b - t-SNE\n",
    "Visualize the same expression data using t-SNE using `perplexity=5`. Then plot it with `perplexity=30`. Based on the plots, comment on the effects of different perplexity values.\n",
    "\n",
    "#### `perplexity=5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b92588-dd4d-4240-894d-6056a507ed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a44131b-41c9-4bdf-b67d-ccf778fdb5c9",
   "metadata": {},
   "source": [
    "#### `perplexity=30`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e4c4e2-93f8-4112-a288-e16fc8b697c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6402c03-e757-4aa4-a753-dc1f11df531c",
   "metadata": {},
   "source": [
    "-insert written answer here-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301ae29d-3154-4326-970a-058ed098dcbe",
   "metadata": {},
   "source": [
    "### Question 2c - UMAP\n",
    "Visualize the same expression data using UMAP with `n_neighbors=2`. Then plot it with `n_neighbors=15`. Based on the plots, comment on the effects of different `n_neighbors` values.\n",
    "\n",
    "#### `n_neighbors=2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae8ea0c-f702-4752-96f4-8995b997cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb87a8b-c612-41c9-a4ef-c81d6bd18731",
   "metadata": {},
   "source": [
    "#### `n_neighbors=15`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f65420-ceac-4296-9de0-31d455b60eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb6b1dc-33a8-4af0-8389-9f2c8e13e9a9",
   "metadata": {},
   "source": [
    "-insert written answer here-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be74bc82-e8bd-4c26-99f0-df3257357afd",
   "metadata": {},
   "source": [
    "### Question 2d - Compare and Contrast\n",
    "In a few sentences, compare and contrast the (1) PCA, (2) t-SNE and (3) UMAP results. Be sure to comment on understandability, relative positioning of clusters, runtime, and any other significant factors that you see. Make sure to also comment on why PCA would be a \"safer\" option for dimensionality reduction than t-SNE or UMAP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54970cd2-2d25-4e02-8205-78302be6c53f",
   "metadata": {},
   "source": [
    "-insert written answer here-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1bffa1-2b1d-4dd0-9299-dd4a9c56d3a5",
   "metadata": {},
   "source": [
    "## Question 3: Supervised Machine Learning\n",
    "We will be training a few different machine learning models of different complexity. For each model, we will be splitting our training data in order to perform 5-fold cross-validation to optimize a parameter of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10de432f-7c34-46ef-96cc-87de2320f296",
   "metadata": {},
   "source": [
    "### Question 3a - Logistic Regression\n",
    "Here we will figure out whether to use L2 regularization or no regularization for logistic regression works better. Use `GridSearchCV` to perform hyperparameter optimization in order to find the best model using 5-fold cross-validation (`cv=5`). We will use `accuracy` for scoring. Using `grid_search_lr.cv_results_`, print out the `mean_test_score` for each parameter and determine which parameter is best. Finally use `grid_search_lr.best_estimator_` which contains the best trained model, and use it to predict the tissue types on the test data (`X_test_scaled`). We can then use these predictions to obtain the final performance using `classification_report()`. If you are stuck, here is a good [tutorial](https://dev.to/anurag629/gridsearchcv-in-scikit-learn-a-comprehensive-guide-2a72) on GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b824c10c-c680-4d18-89bf-eeaf765866bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lr = {\n",
    "    'penalty': [None, 'l2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0cf5ac-0534-4db4-ba22-6c6369bb9068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression() # Define model\n",
    "grid_search_lr = #TODO: Declare GridSearchCV\n",
    "#TODO: Fit GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9473377-748d-4c26-a956-9130151e4887",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search_lr.cv_results_)[['params', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f376f34d-5b67-43cc-bf0e-22b1f818335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = #TODO: Predict using best trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905fd14c-961d-4eac-b70f-b5b93258a289",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(#TODO: parameters for classification report))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaf8a2f-b18f-4bd9-ac03-7039c26f8ea8",
   "metadata": {},
   "source": [
    "### Question 3b - Random Forests\n",
    "Repeat the same steps of 3a with random forests (`RandomForestClassifier()`). We will figure out how many decision trees should be in the forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bf24ee-526f-4b5e-a9e7-23a6d1c551af",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7bb0a8-754b-4144-926d-a5f28680f474",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier()\n",
    "grid_search_rf = #TODO: Declare GridSearchCV\n",
    "#TODO: Fit GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4363f7-351a-4320-94d7-f6887704dc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search_rf.cv_results_)[['params', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e77042-baef-46c0-a58b-89f7024a5ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = #TODO: Predict using best trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d60a22d-ed63-4fc7-8d33-312870f0a677",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(#TODO: parameters for classification report))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c34af78-d55a-4351-af62-ce4f600ebf2d",
   "metadata": {},
   "source": [
    "### Question 3c - Support Vector Machine\n",
    "Repeat the same steps of 3a with support vector machine (`SVC()`). Here, we will determine what is the best kernel to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f930be-b65e-468b-ab8d-ca3bb356a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svc = {\n",
    "    'kernel': ['linear', 'poly', 'rbf']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4ae417-8bcf-486f-8745-1232322b4af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "grid_search_svc = #TODO: Declare GridSearchCV\n",
    "#TODO: Fit GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5120ad-4caa-4504-b89d-575fbc00f508",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search_svc.cv_results_)[['params', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1820332-6996-40a9-b19b-aa124c675840",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds = #TODO: Predict using best trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a27fad-8480-4431-bc6a-2f6bf074d59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(#TODO: parameters for classification report))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a25f91-1025-4613-928a-755f6ed5d6a0",
   "metadata": {},
   "source": [
    "### Question 3d - Compare and Contrast\n",
    "Compare and contrast the results from different models. Be sure to comment on which tissue types are the easiest or hardest to predict overal, runtime, and any other significant factors that you see. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea21f37-4880-4bc5-af4a-b3f9f9457bfa",
   "metadata": {},
   "source": [
    "-insert written answer here-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040c14fc-6368-47ef-8e3e-ee55e4efc5b4",
   "metadata": {},
   "source": [
    "## Question 4: Artificial Neural Network\n",
    "We first need to encode the labels numerically for PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29fcf36-3c0b-4385-91e6-115bef1e506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa4e758-0157-4930-8e84-fd9f47352f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = label_encoder.fit_transform(y_train)  \n",
    "y_test_encoded = label_encoder.transform(y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7c6fd2-f447-4dbd-b431-3a6d548c0418",
   "metadata": {},
   "source": [
    "Then we need to turn everything into a tensor, a special data structure used for artificial neural networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fc5151-754f-42ab-b48d-da4e84ee5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_encoded, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fbbf9c-e8a4-42f2-bac3-fa6525fa007f",
   "metadata": {},
   "source": [
    "### Question 4a - ANN Architecture\n",
    "Given the fully connected ANN architecture below, how many layers are there and how many edges (connections) are between each layer? You can ignore the `BatchNorm1d` and `dropout` layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fb00f1-82df-4db6-9cc5-e0d166a0c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Define layers\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(23878, 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 13)    \n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    # Model for forward propagation\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)  \n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)      \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbff611a-9f33-4a83-a0ce-52015c823471",
   "metadata": {},
   "source": [
    "-insert written answer here-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5818c8e0-52a5-4ded-822c-75de2f18deae",
   "metadata": {},
   "source": [
    "### Question 4b - Training\n",
    "Train the ANN using the code below. Make a plot for the training loss (y-axis) against the number of epochs (x-axis). Comment on whether you think the model has reached a local minimum and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8a8480-173c-44e8-9ec5-e9bcb2773579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor dataset of the training data\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db16161-65d5-4fcb-8fa0-27ae465fa0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataloader to load the data into the neural network in batches\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24452f7c-ffda-41de-b77b-9b3f6421d85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our model\n",
    "model = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ffb086-a50b-441d-aaab-7f37ad0003c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb62099-b44d-433d-abf2-9e05c90d3da3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "# Holds average training loss per epoch\n",
    "training_loss_per_epoch = []\n",
    "# Holds testing loss per epoch\n",
    "testing_loss_per_epoch = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Set the model into training mode\n",
    "    model.train()  \n",
    "    running_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    # Stochastic gradient descent on each batch \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass \n",
    "        output = model(batch_X)\n",
    "        # Compute loss for current batch\n",
    "        loss = criterion(output, batch_y)\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        # Update model parameters \n",
    "        optimizer.step()\n",
    "\n",
    "        # Keep track of loss for each batch\n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    # Calculate average loss per epoch\n",
    "    avg_loss = running_loss / num_batches\n",
    "    training_loss_per_epoch.append(avg_loss)\n",
    "\n",
    "    # Ensure no gradients are computed during evaluation\n",
    "    with torch.no_grad():      \n",
    "        # Forward pass on the entire test set\n",
    "        output_test = model(X_test_tensor)\n",
    "        # Compute loss on the entire test set\n",
    "        avg_test_loss = criterion(output_test, y_test_tensor).item()\n",
    "\n",
    "    testing_loss_per_epoch.append(avg_test_loss)\n",
    "    \n",
    "    # Print epoch and training loss\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {loss:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d88c77-c62d-4873-9701-34c65c12d89a",
   "metadata": {},
   "source": [
    "Let's now look at the training accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc65f075-749f-4a47-b7d3-85ef452071fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model into evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make sure network doesn't compute gradients during evaluation\n",
    "with torch.no_grad():\n",
    "    # Obtaining training accuracy\n",
    "    # Forward pass on training data\n",
    "    output = model(X_train_tensor)\n",
    "\n",
    "    # For each example, get the most likely class (highest probability)\n",
    "    _, predicted_labels = torch.max(output, 1)  \n",
    "\n",
    "    # Compare predicted and true labels\n",
    "    correct = (predicted_labels == y_train_tensor).sum().item()  \n",
    "\n",
    "    # Calculate accuracy\n",
    "    total = y_train_tensor.size(0)  \n",
    "    accuracy = correct / total * 100  \n",
    "    \n",
    "    print(f'Training Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1b01b5-576d-4dd2-84f6-0249ddbcf653",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add code to plot train loss against number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dbe28e-085b-44dc-9251-3468516393fa",
   "metadata": {},
   "source": [
    "-insert written answer here-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41c132f-c652-4415-934c-4d071079e1df",
   "metadata": {},
   "source": [
    "### Question 4c - Evaluation\n",
    "Modify the training accuracy code above to assess the accuracy on the testing dataset (`X_test_tensor`). Print your answers using `classification_report`. Next replot your training loss per epoch, but add the testing loss per epoch as well. Comment on whether you think the model is underfit, overfit or has a good fit. If it is overfit or underfit, what can you do to mitigate this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba0f44f-bd36-49e4-b433-f138abf67fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    #TODO: Code for predicting on test set and comparing against true labels \n",
    "\n",
    "report = classification_report(true_labels, predicted_labels, target_names=label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affd3c9a-2a2e-40e0-bd54-5b04e29176bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a1a46e-6c33-4d33-9382-8c1513ca49e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add code to plot both train and test loss against number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d228ce0-c457-4c27-b081-621a100ad68f",
   "metadata": {},
   "source": [
    "-insert written answer here-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1d1943-40fd-452d-a4c8-4693f4ce583e",
   "metadata": {},
   "source": [
    "## Question 5 - Secret test set\n",
    "### Question 5a - PCA\n",
    "Plot the first two principal components of the training data but this time include the secret test set (`secret.txt`). Label the tissue type as \"???\" as make sure the secret set has different symbol for the data points (e.g. '*')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eebe12-f5e0-4f33-8536-63a35f2a2542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bc7565-144b-4e0d-b3f5-325498fa5476",
   "metadata": {},
   "source": [
    "### Question 5b - UMAP\n",
    "Plot the UMAP embeddings of the training data but this time include the secret test set (`secret.txt`). Label the tissue type as \"???\" as make sure the secret set has different symbol for the data points (e.g. '*')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3c4b85-07cf-4f99-ade2-f7269f518fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3daec99-c418-4477-a6f2-e09020949e0f",
   "metadata": {},
   "source": [
    "### Question 5c - Evaluate\n",
    "Run the ANN on the secret data but output the probability of each predicted label. (Hint: Use `softmax` from `import torch.nn.functional as F` to get probabilities for the output classes then calculate the maximum probability to get the probability of the predicted label). Then make a histogram of the probabilities of predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87b7c97-247d-44a9-85be-d1b401dabaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058a2d03-9ff0-4966-8710-4bc4f1bca5c2",
   "metadata": {},
   "source": [
    "### Question 5d - Assessment\n",
    "Using the PCA, UMAP and probabilities, are there any samples in the secret data that you would not trust the ANN's prediction? Why or why not? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec5ac00-4f1a-428b-92cf-4cc93651412a",
   "metadata": {},
   "source": [
    "-insert written answer here-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
